{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip \n",
    "import ast\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_json2 = []\n",
    "# Abrir el archivo y leer línea por línea\n",
    "with gzip.open('../json/user_reviews.json.gz', 'rt', encoding= 'utf-8') as f2:\n",
    "    for li in f2:\n",
    "        json_linea1 = ast.literal_eval(li)\n",
    "        # Agregar el objeto JSON decodificado a la lista\n",
    "        datos_json2.append(json_linea1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.DataFrame(datos_json2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25799 entries, 0 to 25798\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   user_id   25799 non-null  object\n",
      " 1   user_url  25799 non-null  object\n",
      " 2   reviews   25799 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 604.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(reviews_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.dropna(how='all', inplace=True) # 25799 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para desanidar las reseñas\n",
    "def desanidar_reseñas(row):\n",
    "    user_id = row['user_id']\n",
    "    user_url = row['user_url']\n",
    "    reseñas = row['reviews']\n",
    "    result = []\n",
    "    for idx, res in enumerate(reseñas, start=1):\n",
    "        res['user_id'] = user_id\n",
    "        res['user_url'] = user_url\n",
    "        res['review_id'] = f'{user_id}_review_{idx}'\n",
    "        result.append(res)\n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_dsn = pd.concat(reviews_df.apply(desanidar_reseñas, axis=1).tolist(), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Luka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "umbral_negativo = -0.1\n",
    "umbral_positivo = 0.1\n",
    "\n",
    "\n",
    "for index, row in reviews_dsn.iterrows():\n",
    "    if pd.notnull(row['review']):\n",
    "        sentiment_score = sia.polarity_scores(row['review'])['compound']\n",
    "\n",
    "        if sentiment_score < umbral_negativo:\n",
    "            reviews_dsn.at[index, 'feeling'] = 0\n",
    "        elif sentiment_score > umbral_positivo:\n",
    "            reviews_dsn.at[index, 'feeling'] = 2\n",
    "        else:\n",
    "            reviews_dsn.at[index, 'feeling'] = 1\n",
    "    else:\n",
    "        reviews_dsn.at[index, 'feeling'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(reviews_dsn)\n",
    "pq.write_table(table, \"../data_transformed/reviews.parquet\", compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pq.read_table(\"../data_transformed/reviews.parquet\")\n",
    "user_reviews_df = data.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recommend\n",
       "True     6427\n",
       "False    2820\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = user_reviews_df[user_reviews_df['feeling'] == 0]\n",
    "b = a['recommend'].value_counts()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Luka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Luka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Luka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews_dsn['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.remove('no')\n",
    "stopwords.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_review (review):\n",
    "    review = review.lower()\n",
    "    review = re.sub(\"[^a-zA-Z]\", \" \", str(review)) # Elimina los caracteres que no sean letras o signos de exclamación\n",
    "    review_wt = nltk.tokenize.word_tokenize(review) # Tokeniza y pasa a minúsculas el texto\n",
    "    review_wt = [word for word in review_wt if word not in stopwords] # Elimina las stopwords\n",
    "    review_wt = [lemmatizer.lemmatize(word) for word in review_wt]  # Aplicamos la funcion para buscar la raiz de las palabras\n",
    "    review_wt = \" \".join(review_wt) # Por ultimo volvemos a unir el titular\n",
    "    return review_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_list = []\n",
    "for review in reviews:\n",
    "    review_wt = preproc_review(str(review))\n",
    "    reviews_list.append(review_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de características (Bolsa de palabras):\n",
      " [[0 0 0 ... 0 0 2]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Vocabulario (Tokens únicos): ['ability' 'able' 'absolutely' 'access' 'achievement' 'action' 'actual'\n",
      " 'actually' 'add' 'added' 'addicting' 'addictive' 'adventure' 'age' 'ago'\n",
      " 'ai' 'al' 'alien' 'allows' 'alot' 'alpha' 'alright' 'amazing'\n",
      " 'amazing game' 'amigo' 'animation' 'annoying' 'apart' 'area' 'arma' 'art'\n",
      " 'aspect' 'atmosphere' 'attack' 'away' 'awesome' 'awesome awesome'\n",
      " 'awesome game' 'awsome' 'bad' 'bad bad' 'base' 'based' 'basic'\n",
      " 'basically' 'batman' 'battle' 'beat' 'beautiful' 'begin' 'believe' 'bem'\n",
      " 'best' 'best game' 'beta' 'better' 'big' 'bit' 'black' 'blood' 'bom'\n",
      " 'borderland' 'bored' 'boring' 'bos' 'boss' 'bought' 'bought game' 'break'\n",
      " 'brilliant' 'bring' 'broken' 'bueno' 'bug' 'buggy' 'build' 'building'\n",
      " 'bullet' 'button' 'buy' 'buy game' 'buying' 'called' 'came' 'campaign'\n",
      " 'car' 'card' 'care' 'case' 'casual' 'cause' 'certain' 'challenge'\n",
      " 'challenging' 'chance' 'change' 'character' 'cheap' 'check' 'choice'\n",
      " 'choose' 'city' 'class' 'classic' 'click' 'close' 'cod' 'com' 'combat'\n",
      " 'come' 'coming' 'community' 'como' 'competitive' 'complete' 'completely'\n",
      " 'computer' 'concept' 'console' 'constantly' 'content' 'control'\n",
      " 'controller' 'cool' 'cost' 'counter' 'counter strike' 'couple' 'course'\n",
      " 'crafting' 'crap' 'crash' 'create' 'current' 'da' 'damage' 'damn' 'dark'\n",
      " 'day' 'dayz' 'dead' 'death' 'decent' 'decided' 'definitely' 'depth'\n",
      " 'design' 'despite' 'developer' 'development' 'devs' 'didnt' 'die' 'died'\n",
      " 'different' 'difficult' 'difficulty' 'dlc' 'doesnt' 'dollar' 'dont'\n",
      " 'dota' 'download' 'drop' 'duty' 'early' 'early access' 'easily' 'easy'\n",
      " 'effect' 'el' 'element' 'em' 'en' 'end' 'ending' 'endless' 'enemy'\n",
      " 'engine' 'enjoy' 'enjoyable' 'enjoyed' 'entire' 'environment' 'epic'\n",
      " 'episode' 'especially' 'esse' 'esse jogo' 'esta' 'este' 'eu' 'event'\n",
      " 'example' 'excellent' 'expect' 'experience' 'explore' 'extra' 'extremely'\n",
      " 'eye' 'face' 'fact' 'fallout' 'fan' 'fantastic' 'far' 'fast' 'fast paced'\n",
      " 'favorite' 'favourite' 'favourite game' 'feature' 'feel' 'feel like'\n",
      " 'feeling' 'felt' 'fight' 'fighting' 'final' 'finally' 'fine' 'finish'\n",
      " 'finished' 'fix' 'fixed' 'force' 'fortress' 'forward' 'fps' 'fps game'\n",
      " 'free' 'free play' 'friend' 'friendly' 'frustrating' 'fun' 'fun game'\n",
      " 'fun play' 'funny' 'future' 'game' 'game amazing' 'game awesome'\n",
      " 'game best' 'game better' 'game buy' 'game free' 'game fun' 'game game'\n",
      " 'game good' 'game great' 'game like' 'game look' 'game lot' 'game love'\n",
      " 'game make' 'game mode' 'game need' 'game people' 'game play'\n",
      " 'game played' 'game pretty' 'game really' 'game recommend' 'game steam'\n",
      " 'game time' 'game worth' 'game year' 'gamemodes' 'gameplay' 'gaming'\n",
      " 'gave' 'gear' 'general' 'genre' 'getting' 'given' 'giving' 'glitch'\n",
      " 'goat' 'god' 'going' 'gon' 'gon na' 'good' 'good game' 'got' 'gr'\n",
      " 'graphic' 'great' 'great fun' 'great game' 'greatest' 'grind' 'group'\n",
      " 'gta' 'guess' 'gun' 'guy' 'hacker' 'half' 'half life' 'hand' 'happy'\n",
      " 'hard' 'hat' 'hat hat' 'hate' 'head' 'heap' 'heart' 'heist' 'hell' 'help'\n",
      " 'hero' 'hey' 'high' 'higher' 'highly' 'highly recommend' 'hit' 'hold'\n",
      " 'home' 'honestly' 'hope' 'horrible' 'horror' 'hot' 'hot super' 'hour'\n",
      " 'hour game' 'house' 'http' 'huge' 'idea' 'ign' 'im' 'incredible'\n",
      " 'incredibly' 'indie' 'ing' 'instead' 'intense' 'interesting' 'issue'\n",
      " 'item' 'ive' 'job' 'jogar' 'jogo' 'john' 'join' 'juego' 'jump' 'key'\n",
      " 'kid' 'kill' 'killed' 'killing' 'kind' 'kinda' 'know' 'la' 'lack' 'lag'\n",
      " 'large' 'later' 'le' 'learn' 'learning' 'leave' 'left' 'let' 'level'\n",
      " 'life' 'light' 'like' 'like game' 'liked' 'line' 'literally' 'little'\n",
      " 'live' 'lo' 'load' 'lol' 'long' 'long time' 'longer' 'look' 'look like'\n",
      " 'looking' 'loot' 'los' 'lose' 'lost' 'lot' 'lot fun' 'love' 'love game'\n",
      " 'loved' 'low' 'ma' 'main' 'mais' 'major' 'make' 'make game' 'making'\n",
      " 'man' 'map' 'massive' 'match' 'mate' 'matter' 'maybe' 'mean' 'mechanic'\n",
      " 'menu' 'mind' 'minecraft' 'minute' 'mission' 'mod' 'mode' 'moment'\n",
      " 'money' 'monster' 'month' 'mouse' 'movie' 'muito' 'muito bom'\n",
      " 'multiplayer' 'multiple' 'music' 'muy' 'na' 'need' 'negative' 'new'\n",
      " 'new update' 'nice' 'nice game' 'night' 'non' 'normal' 'note' 'number'\n",
      " 'nyan' 'nyan nyan' 'objective' 'offer' 'oh' 'ok' 'okay' 'old' 'online'\n",
      " 'op' 'open' 'open world' 'opinion' 'option' 'order' 'original' 'ou'\n",
      " 'overall' 'paced' 'pack' 'paid' 'para' 'past' 'patch' 'path' 'pay'\n",
      " 'pay win' 'payday' 'pc' 'people' 'perfect' 'pero' 'person'\n",
      " 'person shooter' 'personally' 'pew' 'pew pew' 'physic' 'pick' 'piece'\n",
      " 'place' 'planet' 'play' 'play friend' 'play game' 'played' 'played game'\n",
      " 'player' 'playing' 'playing game' 'plenty' 'plot' 'plus' 'point' 'por'\n",
      " 'port' 'portal' 'possible' 'potential' 'power' 'pra' 'pretty'\n",
      " 'pretty good' 'previous' 'price' 'pro' 'probably' 'problem' 'progress'\n",
      " 'purchase' 'puzzle' 'pvp' 'quality' 'que' 'quest' 'quick' 'quickly'\n",
      " 'quite' 'race' 'rage' 'random' 'range' 'rank' 'rate' 'rating' 'read'\n",
      " 'reading' 'real' 'realistic' 'really' 'really fun' 'really good'\n",
      " 'really really' 'reason' 'reccomend' 'recomend' 'recomendo' 'recommend'\n",
      " 'recommend game' 'recommended' 'regret' 'release' 'released' 'remember'\n",
      " 'rep' 'rep rep' 'repetitive' 'rest' 'review' 'right' 'robot' 'rock'\n",
      " 'room' 'round' 'rpg' 'run' 'running' 'russian' 'rust' 'sad' 'said' 'sale'\n",
      " 'sandbox' 'save' 'saw' 'say' 'say game' 'saying' 'scary' 'score' 'screen'\n",
      " 'se' 'second' 'seen' 'self' 'sense' 'ser' 'series' 'seriously' 'server'\n",
      " 'set' 'setting' 'ship' 'shit' 'shit shit' 'shoot' 'shooter' 'shooting'\n",
      " 'short' 'shot' 'si' 'similar' 'simple' 'simply' 'simulator' 'single'\n",
      " 'single player' 'skill' 'skin' 'skyrim' 'slow' 'small' 'smooth' 'sniper'\n",
      " 'solid' 'solo' 'soon' 'sort' 'soul' 'sound' 'soundtrack' 'source' 'space'\n",
      " 'spawn' 'special' 'speed' 'spend' 'spent' 'stage' 'stand' 'star' 'start'\n",
      " 'started' 'stealth' 'steam' 'steambored' 'steambored steambored' 'step'\n",
      " 'stop' 'story' 'storyline' 'straight' 'strategy' 'strike' 'stuck' 'stuff'\n",
      " 'stupid' 'style' 'suck' 'super' 'super hot' 'support' 'sure' 'survival'\n",
      " 'survival game' 'survive' 'taking' 'tank' 'te' 'team' 'team fortress'\n",
      " 'tell' 'tem' 'terrarium' 'terrible' 'tf' 'thanks' 'thats' 'thing'\n",
      " 'thing game' 'think' 'thinking' 'thought' 'throw' 'time' 'title' 'ton'\n",
      " 'took' 'total' 'totally' 'town' 'tree' 'tried' 'true' 'truly' 'try'\n",
      " 'trying' 'turn' 'tutorial' 'type' 'um' 'um jogo' 'uma' 'una' 'understand'\n",
      " 'unique' 'unit' 'unless' 'unlock' 'update' 'upgrade' 'use' 'used' 'using'\n",
      " 'usually' 'value' 'valve' 'variety' 'vehicle' 'version' 'video' 'voc'\n",
      " 'voice' 'wait' 'waiting' 'walking' 'wall' 'want' 'want play' 'wanted'\n",
      " 'war' 'warriordragon' 'warriordragon warriordragon' 'waste' 'watch'\n",
      " 'water' 'way' 'weapon' 'week' 'went' 'win' 'window' 'wish' 'wont' 'word'\n",
      " 'work' 'working' 'workshop' 'world' 'worst' 'worth' 'worth money' 'wow'\n",
      " 'wrong' 'xd' 'yeah' 'year' 'year old' 'yes' 'zombie']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Inicializar el vectorizador CountVectorizer para bolsa de palabras\n",
    "vectorizador_bolsa_palabras = CountVectorizer(max_features=750, stop_words=\"english\" , ngram_range=(1,2))\n",
    "\n",
    "# Ajustar y transformar los textos en una matriz de características\n",
    "matriz_caracteristicas_bolsa_palabras = vectorizador_bolsa_palabras.fit_transform(reviews_list)\n",
    "\n",
    "# Obtener el vocabulario (tokens únicos)\n",
    "vocabulario_bolsa_palabras = vectorizador_bolsa_palabras.get_feature_names_out()\n",
    "\n",
    "# Imprimir la matriz de características y el vocabulario\n",
    "print(\"Matriz de características (Bolsa de palabras):\\n\", matriz_caracteristicas_bolsa_palabras.toarray())\n",
    "print(\"Vocabulario (Tokens únicos):\", vocabulario_bolsa_palabras)\n",
    "\n",
    "# # Inicializar el vectorizador TfidfVectorizer para TF-IDF\n",
    "# vectorizador_tfidf = TfidfVectorizer(max_features=1000, stop_words=\"english\" , ngram_range=(1,2))\n",
    "\n",
    "# # Ajustar y transformar los textos en una matriz de características TF-IDF\n",
    "# matriz_caracteristicas_tfidf = vectorizador_tfidf.fit_transform(reviews.tolist())\n",
    "\n",
    "# # Imprimir la matriz de características TF-IDF\n",
    "# print(\"\\nMatriz de características (TF-IDF):\\n\", matriz_caracteristicas_tfidf.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
